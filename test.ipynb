{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f87c66-5540-4a94-bc15-0ef61ece71fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac48a7a5-6c90-424f-90e3-a34432286498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read train dataset and test dataset\n",
    "train = pd.read_csv(\"train_dataset.csv\")\n",
    "test = pd.read_csv(\"test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2596f7c-e2ac-4673-a82b-621a4d99dc36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import all 12 vectorizers\n",
    "train_countvec_director = np.load(\"train_countvec_features_director_name.npy\")\n",
    "train_countvec_actor2 = np.load(\"train_countvec_features_actor_2_name.npy\")\n",
    "train_countvec_actor1 = np.load(\"train_countvec_features_actor_1_name.npy\")\n",
    "test_countvec_director = np.load(\"test_countvec_features_director_name.npy\")\n",
    "test_countvec_actor2 = np.load(\"test_countvec_features_actor_2_name.npy\")\n",
    "test_countvec_actor1 = np.load(\"test_countvec_features_actor_1_name.npy\")\n",
    "\n",
    "train_doc2vec_plot_keywords = np.load(\"train_doc2vec_features_plot_keywords.npy\")\n",
    "test_doc2vec_plot_keywords = np.load(\"test_doc2vec_features_plot_keywords.npy\")\n",
    "train_doc2vec_genre = np.load(\"train_doc2vec_features_genre.npy\")\n",
    "test_doc2vec_genre = np.load(\"test_doc2vec_features_genre.npy\")\n",
    "train_fasttext_title_embeddings = np.load(\"train_fasttext_title_embeddings.npy\")\n",
    "test_fasttext_title_embeddings = np.load(\"test_fasttext_title_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4fa4c4-359b-4164-99a0-7ff743a8bf11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dimension Reduction with Gaussian Random Projection: represent vector values with a single number\n",
    "\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "rp = GaussianRandomProjection(n_components=1)\n",
    "\n",
    "reduced_train_countvec_director = rp.fit_transform(train_countvec_director)\n",
    "reduced_train_countvec_actor1 = rp.fit_transform(train_countvec_actor1)\n",
    "reduced_train_countvec_actor2 = rp.fit_transform(train_countvec_actor2)\n",
    "reduced_train_doc2vec_plot_keywords = rp.fit_transform(train_doc2vec_plot_keywords)\n",
    "reduced_train_doc2vec_genre = rp.fit_transform(train_doc2vec_genre)\n",
    "reduced_train_fasttext_title_embeddings = rp.fit_transform(train_fasttext_title_embeddings)\n",
    "train_countvec_director_lst = []\n",
    "train_countvec_actor1_lst = []\n",
    "train_countvec_actor2_lst = []\n",
    "train_doc2vec_plot_keywords_lst = []\n",
    "train_doc2vec_genre_lst = []\n",
    "train_fasttext_title_embeddings_lst = []\n",
    "for i in range(len(reduced_train_countvec_director)):\n",
    "    train_countvec_director_lst.append(reduced_train_countvec_director[i][0])\n",
    "    train_countvec_actor1_lst.append(reduced_train_countvec_actor1[i][0])\n",
    "    train_countvec_actor2_lst.append(reduced_train_countvec_actor2[i][0])\n",
    "    train_doc2vec_plot_keywords_lst.append(reduced_train_doc2vec_plot_keywords[i][0])\n",
    "    train_doc2vec_genre_lst.append(reduced_train_doc2vec_genre[i][0])\n",
    "    train_fasttext_title_embeddings_lst.append(train_fasttext_title_embeddings[i][0])\n",
    "train['director_name'] = train_countvec_director_lst\n",
    "train['actor_1_name'] = train_countvec_actor1_lst\n",
    "train['actor_2_name'] = train_countvec_actor2_lst\n",
    "train['plot_keywords'] = train_doc2vec_plot_keywords_lst\n",
    "train['genres'] = train_doc2vec_genre_lst\n",
    "train['title_embedding'] = train_fasttext_title_embeddings_lst\n",
    "\n",
    "reduced_test_countvec_director = rp.fit_transform(test_countvec_director)\n",
    "reduced_test_countvec_actor1 = rp.fit_transform(test_countvec_actor1)\n",
    "reduced_test_countvec_actor2 = rp.fit_transform(test_countvec_actor2)\n",
    "reduced_test_doc2vec_plot_keywords = rp.fit_transform(test_doc2vec_plot_keywords)\n",
    "reduced_test_doc2vec_genre = rp.fit_transform(test_doc2vec_genre)\n",
    "reduced_test_fasttext_title_embeddings = rp.fit_transform(test_fasttext_title_embeddings)\n",
    "test_countvec_director_lst = []\n",
    "test_countvec_actor1_lst = []\n",
    "test_countvec_actor2_lst = []\n",
    "test_doc2vec_plot_keywords_lst = []\n",
    "test_doc2vec_genre_lst = []\n",
    "test_fasttext_title_embeddings_lst = []\n",
    "for i in range(len(reduced_test_countvec_director)):\n",
    "    test_countvec_director_lst.append(reduced_test_countvec_director[i][0])\n",
    "    test_countvec_actor1_lst.append(reduced_test_countvec_actor1[i][0])\n",
    "    test_countvec_actor2_lst.append(reduced_test_countvec_actor2[i][0])\n",
    "    test_doc2vec_plot_keywords_lst.append(reduced_test_doc2vec_plot_keywords[i][0])\n",
    "    test_doc2vec_genre_lst.append(reduced_test_doc2vec_genre[i][0])\n",
    "    test_fasttext_title_embeddings_lst.append(test_fasttext_title_embeddings[i][0])\n",
    "test['director_name'] = test_countvec_director_lst\n",
    "test['actor_1_name'] = test_countvec_actor1_lst\n",
    "test['actor_2_name'] = test_countvec_actor2_lst\n",
    "test['plot_keywords'] = test_doc2vec_plot_keywords_lst\n",
    "test['genres'] = test_doc2vec_genre_lst\n",
    "test['title_embedding'] = test_fasttext_title_embeddings_lst\n",
    "\n",
    "#drop features with no vectorizer provided\n",
    "train = train.drop(['movie_title','actor_3_name'],axis=1)\n",
    "test = test.drop(['movie_title','actor_3_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59e7b328-b770-49e6-be15-8451d4324b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split data into X and y without id\n",
    "X_train = train.iloc[:,1:-1]\n",
    "y_train = train.iloc[:,-1]\n",
    "X_test = test.iloc[:,1:]\n",
    "feat_num = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc53d419-7536-4cbe-bc2a-da6b98f215dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#representing categorical features with numbers\n",
    "language_dict = {}\n",
    "language_num = 0\n",
    "country_dict = {}\n",
    "country_num = 0\n",
    "content_rating_dict = {}\n",
    "content_rating_num = 0\n",
    "for language in X_train['language']:\n",
    "    if language not in language_dict:\n",
    "        language_dict[language] = language_num + 1\n",
    "        language_num += 1\n",
    "for language in X_test['language']:\n",
    "    if language not in language_dict:\n",
    "        language_dict[language] = language_num + 1\n",
    "        language_num += 1\n",
    "\n",
    "for country in X_train['country']:\n",
    "    if country not in country_dict:\n",
    "        country_dict[country] = country_num + 1\n",
    "        country_num += 1\n",
    "for country in X_test['country']:\n",
    "    if country not in country_dict:\n",
    "        country_dict[country] = country_num + 1\n",
    "        country_num += 1\n",
    "\n",
    "for content_rating in X_train['content_rating']:\n",
    "    if content_rating not in content_rating_dict:\n",
    "        content_rating_dict[content_rating] = content_rating_num + 1\n",
    "        content_rating_num += 1\n",
    "for content_rating in X_test['content_rating']:\n",
    "    if content_rating not in content_rating_dict:\n",
    "        content_rating_dict[content_rating] = content_rating_num + 1\n",
    "        content_rating_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "794bfce2-c6b7-4d0f-932d-12031fe60a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train['language'] = [language_dict.get(language,language) for language in X_train['language']]\n",
    "X_test['language'] = [language_dict.get(language,language) for language in X_test['language']]\n",
    "X_train['country'] = [country_dict.get(country,country) for country in X_train['country']]\n",
    "X_test['country'] = [country_dict.get(country,country) for country in X_test['country']]\n",
    "X_train['content_rating'] = [content_rating_dict.get(content_rating,content_rating) for content_rating in X_train['content_rating']]\n",
    "X_test['content_rating'] = [content_rating_dict.get(content_rating,content_rating) for content_rating in X_test['content_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0644d1c-cd15-445b-bafe-d26f0735e19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#feature selection: find out which feature is most influential to imdb score\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectoriser = CountVectorizer()\n",
    "x2 = SelectKBest(f_classif, k=20)\n",
    "X_train_x2 = x2.fit_transform(X_train,y_train)\n",
    "mask = x2.get_support()\n",
    "se = X_train.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "318a7736-ea99-4c55-9acb-a5af71d52062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#kNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN.fit(X_train,y_train)\n",
    "y_pred_KNN = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15cc51b4-63da-4cbb-8249-775a498b0345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f0047ef-b05f-441a-832e-753b4bb40181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='rbf', gamma='scale')\n",
    "svm.fit(X_train,y_train)\n",
    "y_predict_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9205efa-cdc6-4edb-ba7f-a1b74effdcf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "KNN_imdb_score_binned = pd.DataFrame(y_pred_KNN, columns = ['imdb_score_binned'])\n",
    "KNN_r = pd.concat([test['id'],KNN_imdb_score_binned], axis=1)\n",
    "csv_path_KNN = 'KNN.csv'\n",
    "KNN_r.to_csv(csv_path_KNN, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5e348aa-e72b-469e-bbf5-73297076b152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_imdb_score_binned = pd.DataFrame(y_pred_lr, columns = ['imdb_score_binned'])\n",
    "lr_r = pd.concat([test['id'],lr_imdb_score_binned], axis=1)\n",
    "csv_path_lr = 'lr.csv'\n",
    "lr_r.to_csv(csv_path_lr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cafd0bb-f522-482e-8e8a-3f918b81e576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_imdb_score_binned = pd.DataFrame(y_predict_svm, columns = ['imdb_score_binned'])\n",
    "svm_r = pd.concat([test['id'],svm_imdb_score_binned], axis=1)\n",
    "csv_path_svm = 'svm.csv'\n",
    "svm_r.to_csv(csv_path_svm, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90c4ff-ee98-4994-a39f-4185edaa5139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
